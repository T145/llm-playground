base_model: Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2
dtype: bfloat16
merge_method: breadcrumbs_ties
tokenizer:
  source: union
parameters:
  int8_mask: true
  #normalize: true
  random_seed: 145
models:
  - model: arcee-ai/Llama-3.1-SuperNova-Lite
    parameters:
      weight:
        - filter: lm_head
          value: 0.0
        - filter: self_attn.o_proj
          value: 0.0
        - filter: mlp.down_proj
          value: 0.0
        - value: 0.42
      density: 0.9
      gamma: 0.01
  - model: VAGOsolutions/Llama-3.1-SauerkrautLM-8b-Instruct
    parameters:
      weight:
        - filter: lm_head
          value: 0.0
        - filter: self_attn.o_proj
          value: 0.0
        - filter: mlp.down_proj
          value: 0.0
        - value: 0.33
      density: 0.9
      gamma: 0.01
  - model: unsloth/Llama-3.1-Storm-8B
    parameters:
      weight:
        - filter: lm_head
          value: 0.0
        - filter: self_attn.o_proj
          value: 0.0
        - filter: mlp.down_proj
          value: 0.0
        - value: 0.25
      density: 0.9
      gamma: 0.01
