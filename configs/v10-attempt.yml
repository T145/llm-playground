# Generated by ZEUS 8B V10
base_model: unsloth/Meta-Llama-3.1-8B-Instruct
dtype: bfloat16
merge_method: dare_ties
slices:
  - sources:
      - layer_range: [0, 32]
        model: akjindal53244/Llama-3.1-Storm-8B
        parameters:
          density: 0.85
          weight: 0.28
      - layer_range: [0, 32]
        model: arcee-ai/Llama-3.1-SuperNova-Lite
        parameters:
          density: 0.82
          weight: 0.31
      - layer_range: [0, 32]
        model: SicariusSicariiStuff/LLAMA-3_8B_Unaligned_BETA
        parameters:
          density: 0.77
          weight: 0.41
      - layer_range: [0, 32]
        model: unsloth/Meta-Llama-3.1-8B-Instruct
  - sources:
      - layer_range: [0, 32]
        model: unsloth/Llama-3.1-Storm-8B
        parameters:
          density: 0.95
          weight: 0.32
      - layer_range: [0, 32]
        model: arcee-ai/Llama-3.1-SuperNova-Lite
        parameters:
          density: 0.9
          weight: 0.28
      - layer_range: [0, 32]
        model: Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2
        parameters:
          density: 0.92
          weight: 0.4
      - layer_range: [0, 32]
        model: unsloth/Meta-Llama-3.1-8B-Instruct
tokenizer_source: base
parameters:
  int8_mask: 1.0
  normalize: 1.0
  random_seed: 145.0
